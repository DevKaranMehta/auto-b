from flask import Flask, render_template, request, redirect, url_for, flash, jsonify, session, abort
from werkzeug.security import generate_password_hash, check_password_hash
from datetime import datetime, timedelta
from functools import wraps
import psycopg2
from psycopg2.extras import RealDictCursor
import re
import os
import csv
import io
import requests
from xml.etree.ElementTree import Element, SubElement, tostring
from xml.dom import minidom

app = Flask(__name__)
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'blockchain-news-secret-key-2024')

def get_db_connection():
    try:
        conn = psycopg2.connect(
            host='n8n-postgres',
            port='5432',
            database='blockchain_news',
            user='n8n_user',
            password='7661607468AAHE5Xc97@123??',
            connect_timeout=10,
            cursor_factory=RealDictCursor
        )
        return conn
    except Exception as e:
        print(f"Database connection failed: {e}")
        return None

def create_slug(title):
    slug = re.sub(r'[^\w\s-]', '', title.lower())
    slug = re.sub(r'[-\s]+', '-', slug)
    return slug.strip('-')

def login_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'admin_logged_in' not in session:
            return redirect(url_for('admin_login'))
        return f(*args, **kwargs)
    return decorated_function

def track_analytics(event_type, page_url=None):
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO analytics (event_type, page_url, ip_address, user_agent) 
                VALUES (%s, %s, %s, %s)
            """, (event_type, page_url or request.url, request.remote_addr, request.headers.get('User-Agent', '')))
            conn.commit()
            cursor.close()
            conn.close()
    except:
        pass

# Public Routes
@app.route('/')
def index():
    track_analytics('pageview', '/')
    page = request.args.get('page', 1, type=int)
    category_slug = request.args.get('category')
    search = request.args.get('search', '')
    
    try:
        conn = get_db_connection()
        if not conn:
            return render_template('public/index.html', posts=[], categories=[], featured_post=None, popular_posts=[])
        
        cursor = conn.cursor()
        
        # Get categories
        cursor.execute("SELECT * FROM category ORDER BY name")
        categories = cursor.fetchall()
        
        # Base query for posts
        query = "SELECT p.*, c.name as category_name, c.color as category_color FROM post p LEFT JOIN category c ON p.category_id = c.id WHERE p.is_published = TRUE"
        params = []
        
        if category_slug:
            query += " AND c.slug = %s"
            params.append(category_slug)
        
        if search:
            query += " AND (p.title ILIKE %s OR p.content ILIKE %s)"
            params.extend([f'%{search}%', f'%{search}%'])
        
        query += " ORDER BY p.created_at DESC LIMIT 10 OFFSET %s"
        params.append((page - 1) * 10)
        
        cursor.execute(query, params)
        posts = cursor.fetchall()
        
        # Get featured post
        cursor.execute("SELECT p.*, c.name as category_name, c.color as category_color FROM post p LEFT JOIN category c ON p.category_id = c.id WHERE p.is_featured = TRUE AND p.is_published = TRUE LIMIT 1")
        featured_post = cursor.fetchone()
        
        # Get popular posts
        cursor.execute("SELECT p.*, c.name as category_name FROM post p LEFT JOIN category c ON p.category_id = c.id WHERE p.is_published = TRUE ORDER BY p.views DESC LIMIT 5")
        popular_posts = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        return render_template('public/index.html', 
                             posts=posts, 
                             categories=categories,
                             featured_post=featured_post,
                             popular_posts=popular_posts,
                             current_category=category_slug,
                             search=search)
    except Exception as e:
        print(f"Error in index: {e}")
        return render_template('public/index.html', posts=[], categories=[], featured_post=None, popular_posts=[])

@app.route('/post/<slug>')
def post_detail(slug):
    """Fixed post detail route with proper error handling"""
    try:
        conn = get_db_connection()
        if not conn:
            print("Database connection failed")
            abort(500)
        
        cursor = conn.cursor()
        
        # Get post and increment views
        cursor.execute("""
            SELECT p.*, c.name as category_name, c.color as category_color 
            FROM post p 
            LEFT JOIN category c ON p.category_id = c.id 
            WHERE p.slug = %s AND p.is_published = TRUE
        """, (slug,))
        post = cursor.fetchone()
        
        if not post:
            print(f"Post not found: {slug}")
            cursor.close()
            conn.close()
            abort(404)
        
        # Increment view count
        cursor.execute("UPDATE post SET views = views + 1 WHERE id = %s", (post['id'],))
        
        # Get related posts
        cursor.execute("""
            SELECT p.*, c.name as category_name FROM post p 
            LEFT JOIN category c ON p.category_id = c.id 
            WHERE p.id != %s AND p.category_id = %s AND p.is_published = TRUE 
            ORDER BY p.created_at DESC LIMIT 3
        """, (post['id'], post['category_id']))
        related_posts = cursor.fetchall()
        
        conn.commit()
        cursor.close()
        conn.close()
        
        track_analytics('post_view', f'/post/{slug}')
        
        return render_template('public/post_detail.html', post=post, related_posts=related_posts)
    except Exception as e:
        print(f"Error in post_detail: {e}")
        abort(404)

@app.route('/search')
def search():
    query = request.args.get('q', '')
    page = request.args.get('page', 1, type=int)
    
    try:
        conn = get_db_connection()
        if not conn:
            return render_template('public/search.html', posts=[], query=query)
        
        cursor = conn.cursor()
        
        if query:
            cursor.execute("""
                SELECT p.*, c.name as category_name FROM post p 
                LEFT JOIN category c ON p.category_id = c.id 
                WHERE (p.title ILIKE %s OR p.content ILIKE %s) AND p.is_published = TRUE 
                ORDER BY p.created_at DESC LIMIT 10 OFFSET %s
            """, (f'%{query}%', f'%{query}%', (page - 1) * 10))
            posts = cursor.fetchall()
        else:
            posts = []
        
        cursor.close()
        conn.close()
        
        track_analytics('search', f'/search?q={query}')
        
        return render_template('public/search.html', posts=posts, query=query)
    except Exception as e:
        print(f"Error in search: {e}")
        return render_template('public/search.html', posts=[], query=query)

@app.route('/sitemap.xml')
def sitemap():
    try:
        conn = get_db_connection()
        if not conn:
            return "Error generating sitemap", 500
        
        cursor = conn.cursor()
        cursor.execute("SELECT slug, updated_at FROM post WHERE is_published = TRUE ORDER BY updated_at DESC")
        posts = cursor.fetchall()
        cursor.close()
        conn.close()
        
        urlset = Element('urlset')
        urlset.set('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')
        
        url = SubElement(urlset, 'url')
        SubElement(url, 'loc').text = 'https://blockchainlatestnews.com'
        SubElement(url, 'lastmod').text = datetime.utcnow().strftime('%Y-%m-%d')
        
        for post in posts:
            url = SubElement(urlset, 'url')
            SubElement(url, 'loc').text = f"https://blockchainlatestnews.com/post/{post['slug']}"
            SubElement(url, 'lastmod').text = post['updated_at'].strftime('%Y-%m-%d')
        
        xml_str = minidom.parseString(tostring(urlset)).toprettyxml(indent="  ")
        
        response = app.make_response(xml_str)
        response.headers['Content-Type'] = 'application/xml'
        return response
        
    except Exception as e:
        print(f"Error generating sitemap: {e}")
        return "Error generating sitemap", 500

@app.route('/newsletter/subscribe', methods=['POST'])
def newsletter_subscribe():
    email = request.form.get('email')
    
    if not email:
        return jsonify({'success': False, 'message': 'Email is required'})
    
    try:
        conn = get_db_connection()
        if not conn:
            return jsonify({'success': False, 'message': 'Database error'})
        
        cursor = conn.cursor()
        
        cursor.execute("SELECT id FROM newsletter WHERE email = %s", (email,))
        if cursor.fetchone():
            return jsonify({'success': False, 'message': 'Email already subscribed'})
        
        cursor.execute("INSERT INTO newsletter (email) VALUES (%s)", (email,))
        conn.commit()
        cursor.close()
        conn.close()
        
        track_analytics('newsletter_signup')
        
        return jsonify({'success': True, 'message': 'Successfully subscribed!'})
    except Exception as e:
        return jsonify({'success': False, 'message': 'An error occurred'})

# Admin Routes
@app.route('/admin')
@login_required
def admin_dashboard():
    try:
        conn = get_db_connection()
        if not conn:
            return "Database connection failed"
        
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM post")
        total_posts = cursor.fetchone()['count']
        
        cursor.execute("SELECT COUNT(*) FROM category")
        total_categories = cursor.fetchone()['count']
        
        cursor.execute("SELECT COUNT(*) FROM newsletter WHERE is_active = TRUE")
        total_subscribers = cursor.fetchone()['count']
        
        cursor.execute("SELECT p.*, c.name as category_name FROM post p LEFT JOIN category c ON p.category_id = c.id ORDER BY p.created_at DESC LIMIT 5")
        recent_posts = cursor.fetchall()
        
        week_ago = datetime.utcnow() - timedelta(days=7)
        cursor.execute("SELECT COUNT(*) FROM analytics WHERE event_type = 'pageview' AND created_at >= %s", (week_ago,))
        weekly_views_result = cursor.fetchone()
        weekly_views = weekly_views_result['count'] if weekly_views_result else 0
        
        cursor.close()
        conn.close()
        
        return render_template('admin/dashboard.html',
                             total_posts=total_posts,
                             total_categories=total_categories,
                             total_subscribers=total_subscribers,
                             recent_posts=recent_posts,
                             weekly_views=weekly_views)
    except Exception as e:
        return f"Admin dashboard error: {str(e)}"

@app.route('/admin/login', methods=['GET', 'POST'])
def admin_login():
    if request.method == 'POST':
        username = request.form['username']
        password = request.form['password']
        
        try:
            conn = get_db_connection()
            if not conn:
                flash('Database connection error')
                return render_template('admin/login.html')
            
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM admin_user WHERE username = %s", (username,))
            user = cursor.fetchone()
            
            if user and check_password_hash(user['password_hash'], password):
                session['admin_logged_in'] = True
                session['admin_username'] = username
                cursor.close()
                conn.close()
                return redirect(url_for('admin_dashboard'))
            else:
                flash('Invalid username or password')
            
            cursor.close()
            conn.close()
        except Exception as e:
            flash(f'Login error: {str(e)}')
    
    return render_template('admin/login.html')

@app.route('/admin/logout')
def admin_logout():
    session.pop('admin_logged_in', None)
    session.pop('admin_username', None)
    return redirect(url_for('index'))

@app.route('/admin/posts')
@login_required
def admin_posts():
    try:
        conn = get_db_connection()
        if not conn:
            return "Database connection failed"
        
        cursor = conn.cursor()
        cursor.execute("SELECT p.*, c.name as category_name FROM post p LEFT JOIN category c ON p.category_id = c.id ORDER BY p.created_at DESC")
        posts = cursor.fetchall()
        cursor.close()
        conn.close()
        
        return render_template('admin/posts.html', posts=posts)
    except Exception as e:
        return f"Posts error: {str(e)}"

@app.route('/admin/posts/new', methods=['GET', 'POST'])
@login_required
def admin_new_post():
    if request.method == 'POST':
        title = request.form['title']
        content = request.form['content']
        excerpt = request.form.get('excerpt', '')
        category_id = request.form.get('category_id') or None
        is_featured = 'is_featured' in request.form
        is_published = 'is_published' in request.form
        
        slug = create_slug(title)
        
        try:
            conn = get_db_connection()
            if not conn:
                flash('Database connection error')
                return redirect(url_for('admin_posts'))
            
            cursor = conn.cursor()
            
            # Ensure unique slug
            counter = 1
            original_slug = slug
            while True:
                cursor.execute("SELECT id FROM post WHERE slug = %s", (slug,))
                if not cursor.fetchone():
                    break
                slug = f"{original_slug}-{counter}"
                counter += 1
            
            cursor.execute("""
                INSERT INTO post (title, slug, content, excerpt, category_id, is_featured, is_published, author) 
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (title, slug, content, excerpt, category_id, is_featured, is_published, session.get('admin_username', 'Admin')))
            
            conn.commit()
            cursor.close()
            conn.close()
            
            flash('Post created successfully!')
            return redirect(url_for('admin_posts'))
        except Exception as e:
            flash(f'Error creating post: {str(e)}')
    
    try:
        conn = get_db_connection()
        if not conn:
            return "Database connection failed"
        
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM category ORDER BY name")
        categories = cursor.fetchall()
        cursor.close()
        conn.close()
        
        return render_template('admin/post_form.html', categories=categories)
    except Exception as e:
        return f"Form error: {str(e)}"

@app.route('/admin/posts/<int:id>/edit', methods=['GET', 'POST'])
@login_required
def admin_edit_post(id):
    try:
        conn = get_db_connection()
        if not conn:
            return "Database connection failed"
        
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM post WHERE id = %s", (id,))
        post = cursor.fetchone()
        
        if not post:
            abort(404)
        
        if request.method == 'POST':
            title = request.form['title']
            content = request.form['content']
            excerpt = request.form.get('excerpt', '')
            category_id = request.form.get('category_id') or None
            is_featured = 'is_featured' in request.form
            is_published = 'is_published' in request.form
            
            cursor.execute("""
                UPDATE post SET title = %s, content = %s, excerpt = %s, category_id = %s, 
                is_featured = %s, is_published = %s, updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
            """, (title, content, excerpt, category_id, is_featured, is_published, id))
            
            conn.commit()
            cursor.close()
            conn.close()
            
            flash('Post updated successfully!')
            return redirect(url_for('admin_posts'))
        
        cursor.execute("SELECT * FROM category ORDER BY name")
        categories = cursor.fetchall()
        cursor.close()
        conn.close()
        
        return render_template('admin/post_form.html', post=post, categories=categories)
    except Exception as e:
        return f"Edit error: {str(e)}"

@app.route('/admin/posts/<int:id>/delete', methods=['POST'])
@login_required
def admin_delete_post(id):
    try:
        conn = get_db_connection()
        if not conn:
            flash('Database connection error')
            return redirect(url_for('admin_posts'))
        
        cursor = conn.cursor()
        cursor.execute("DELETE FROM post WHERE id = %s", (id,))
        conn.commit()
        cursor.close()
        conn.close()
        
        flash('Post deleted successfully!')
    except Exception as e:
        flash(f'Error deleting post: {str(e)}')
    
    return redirect(url_for('admin_posts'))

@app.route('/admin/settings')
@login_required
def admin_settings():
    try:
        conn = get_db_connection()
        if not conn:
            return "Database connection failed"
        
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM settings ORDER BY setting_key")
        settings_list = cursor.fetchall()
        
        # Convert to dictionary for easier access
        settings = {}
        for setting in settings_list:
            settings[setting['setting_key']] = setting['setting_value']
        
        cursor.close()
        conn.close()
        
        return render_template('admin/settings.html', settings=settings)
    except Exception as e:
        return f"Settings error: {str(e)}"

if __name__ == '__main__':
    print("ðŸš€ Starting Blockchain Latest News Platform...")
    print("ðŸŒ Public: https://blockchainlatestnews.com")
    print("ðŸ” Admin: https://blockchainlatestnews.com/admin")
    app.run(host='0.0.0.0', port=5000, debug=False)

@app.route('/admin/topics')
@login_required
def admin_topics():
    try:
        conn = get_db_connection()
        if not conn:
            return "Database connection failed"
        
        cursor = conn.cursor()
        cursor.execute("SELECT t.*, c.name as category_name FROM topics t LEFT JOIN category c ON t.category_id = c.id ORDER BY t.created_at DESC")
        topics = cursor.fetchall()
        
        cursor.execute("SELECT * FROM category ORDER BY name")
        categories = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        return render_template('admin/topics.html', topics=topics, categories=categories)
    except Exception as e:
        return f"Topics error: {str(e)}"

@app.route('/admin/topics/add', methods=['POST'])
@login_required
def admin_add_topic():
    try:
        topic_name = request.form.get('topic_name', '').strip()
        category_id = request.form.get('category_id') or None
        is_active = 'is_active' in request.form
        
        if not topic_name:
            flash('Topic name is required')
            return redirect(url_for('admin_topics'))
        
        conn = get_db_connection()
        if not conn:
            flash('Database connection error')
            return redirect(url_for('admin_topics'))
        
        cursor = conn.cursor()
        cursor.execute("INSERT INTO topics (name, category_id, is_active) VALUES (%s, %s, %s)", 
                      (topic_name, category_id, is_active))
        conn.commit()
        cursor.close()
        conn.close()
        
        flash('Topic added successfully!')
        return redirect(url_for('admin_topics'))
    except Exception as e:
        flash(f'Error adding topic: {str(e)}')
        return redirect(url_for('admin_topics'))

@app.route('/admin/topics/import', methods=['POST'])
@login_required
def import_topics():
    try:
        if 'csv_file' not in request.files:
            flash('No CSV file uploaded')
            return redirect(url_for('admin_topics'))
        
        file = request.files['csv_file']
        if file.filename == '':
            flash('No file selected')
            return redirect(url_for('admin_topics'))
        
        stream = io.StringIO(file.stream.read().decode("UTF8"), newline=None)
        csv_input = csv.reader(stream)
        
        conn = get_db_connection()
        if not conn:
            flash('Database connection error')
            return redirect(url_for('admin_topics'))
        
        cursor = conn.cursor()
        imported_count = 0
        
        for row in csv_input:
            if len(row) >= 2:
                topic_name = row[0].strip()
                category_id = int(row[1]) if row[1].isdigit() else None
                
                cursor.execute("SELECT id FROM topics WHERE name = %s", (topic_name,))
                if not cursor.fetchone():
                    cursor.execute("INSERT INTO topics (name, category_id, is_active) VALUES (%s, %s, %s)", 
                                  (topic_name, category_id, True))
                    imported_count += 1
        
        conn.commit()
        cursor.close()
        conn.close()
        
        flash(f'Successfully imported {imported_count} topics!')
        return redirect(url_for('admin_topics'))
        
    except Exception as e:
        flash(f'Error importing topics: {str(e)}')
        return redirect(url_for('admin_topics'))

@app.route('/admin/settings/update', methods=['POST'])
@login_required
def update_settings():
    try:
        conn = get_db_connection()
        if not conn:
            flash('Database connection error', 'error')
            return redirect(url_for('admin_settings'))
        
        cursor = conn.cursor()
        
        # Get all form data
        settings_data = {
            'site_name': request.form.get('site_name', ''),
            'site_description': request.form.get('site_description', ''),
            'posts_per_page': request.form.get('posts_per_page', '10'),
            'openai_api_key': request.form.get('openai_api_key', ''),
            'content_freshness_days': request.form.get('content_freshness_days', '7'),
            'ai_generation_enabled': 'true' if 'ai_generation_enabled' in request.form else 'false',
            'auto_publish_enabled': 'true' if 'auto_publish_enabled' in request.form else 'false',
            'posts_per_day': request.form.get('posts_per_day', '3'),
            'generation_schedule_time': request.form.get('generation_schedule_time', '09:00'),
            'generation_interval_hours': request.form.get('generation_interval_hours', '24'),
            'weekend_generation': 'true' if 'weekend_generation' in request.form else 'false',
        }
        
        # Update each setting
        for key, value in settings_data.items():
            cursor.execute("""
                INSERT INTO settings (setting_key, setting_value) 
                VALUES (%s, %s)
                ON CONFLICT (setting_key) DO UPDATE SET 
                setting_value = EXCLUDED.setting_value,
                updated_at = CURRENT_TIMESTAMP
            """, (key, value))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        flash('Settings updated successfully!', 'success')
        return redirect(url_for('admin_settings'))
        
    except Exception as e:
        flash(f'Error updating settings: {str(e)}', 'error')
        return redirect(url_for('admin_settings'))

import threading
import time
import random
from datetime import datetime, timedelta
import schedule

def generate_ai_content_advanced(topic_name, category_name="Blockchain"):
    """Enhanced AI content generation with better structure"""
    try:
        # For now, we'll use a sophisticated template system
        # In production, replace this with actual OpenAI API calls
        
        content_templates = {
            "defi": {
                "intros": [
                    f"The {topic_name} ecosystem continues to evolve at breakneck speed",
                    f"Recent developments in {topic_name} have caught the attention of institutional investors",
                    f"Market analysts are closely watching {topic_name} as it reaches new milestones"
                ],
                "sections": [
                    "Market Performance and Key Metrics",
                    "Technical Analysis and Price Movements", 
                    "Institutional Adoption Trends",
                    "Developer Activity and Protocol Updates",
                    "Future Outlook and Predictions"
                ]
            },
            "enterprise": {
                "intros": [
                    f"Enterprise adoption of {topic_name} technology is accelerating",
                    f"Major corporations are integrating {topic_name} solutions",
                    f"The business case for {topic_name} implementation grows stronger"
                ],
                "sections": [
                    "Corporate Implementation Strategies",
                    "ROI and Business Benefits",
                    "Integration Challenges and Solutions",
                    "Industry Success Stories",
                    "Future Enterprise Trends"
                ]
            },
            "regulation": {
                "intros": [
                    f"Regulatory frameworks around {topic_name} are taking shape globally",
                    f"Policymakers are crafting new guidelines for {topic_name} oversight",
                    f"The regulatory landscape for {topic_name} continues to evolve"
                ],
                "sections": [
                    "Current Regulatory Environment",
                    "Compliance Requirements and Guidelines",
                    "Global Policy Developments",
                    "Industry Response and Adaptation",
                    "Regulatory Outlook and Implications"
                ]
            }
        }
        
        # Choose template based on category
        template_key = category_name.lower() if category_name.lower() in content_templates else "defi"
        template = content_templates[template_key]
        
        # Generate title
        title_options = [
            f"{topic_name} Reaches New Heights: Comprehensive Market Analysis",
            f"Breaking: {topic_name} Shows Strong Growth Momentum in Q4 2024",
            f"{topic_name} Market Update: Key Developments and Future Prospects",
            f"Deep Dive: {topic_name} Ecosystem Expansion and Investment Trends",
            f"{topic_name} Weekly Report: Performance Metrics and Strategic Insights"
        ]
        
        title = random.choice(title_options)
        
        # Generate content
        intro = random.choice(template["intros"])
        sections = template["sections"]
        
        content_parts = [f"<h3>Executive Summary</h3>"]
        content_parts.append(f"<p>{intro}. This comprehensive analysis examines the current state of the {topic_name} market, recent developments, and future prospects for investors and stakeholders.</p>")
        
        for section in sections:
            content_parts.append(f"<h3>{section}</h3>")
            content_parts.append(f"<p>Recent data indicates significant progress in {topic_name} adoption, with key metrics showing {random.choice(['25%', '30%', '35%', '40%'])} growth over the past {random.choice(['month', 'quarter', '90 days'])}. Industry experts note that {topic_name} continues to demonstrate strong fundamentals and increasing market confidence.</p>")
            
            if random.choice([True, False]):
                content_parts.append("<ul>")
                for _ in range(random.randint(2, 4)):
                    content_parts.append(f"<li>Enhanced security protocols and improved user experience</li>")
                    content_parts.append(f"<li>Growing institutional interest and adoption rates</li>")
                    content_parts.append(f"<li>Strategic partnerships and ecosystem expansion</li>")
                content_parts.append("</ul>")
        
        content_parts.append("<h3>Conclusion</h3>")
        content_parts.append(f"<p>The {topic_name} sector remains well-positioned for continued growth, with strong technical fundamentals, increasing adoption, and positive market sentiment. Stakeholders should monitor upcoming developments and consider strategic positioning for the next phase of market expansion.</p>")
        
        content = "\n".join(content_parts)
        
        # Generate excerpt
        excerpt = f"Comprehensive analysis of {topic_name} market trends, performance metrics, and future outlook. Key insights into adoption rates, institutional interest, and strategic developments in the evolving blockchain landscape."
        
        return {
            'title': title,
            'content': content,
            'excerpt': excerpt,
            'reading_time': random.randint(5, 12)
        }
        
    except Exception as e:
        print(f"AI content generation failed: {e}")
        return None

def generate_posts_from_topics():
    """Generate AI posts based on active topics and settings"""
    try:
        print("ðŸ¤– Starting AI content generation...")
        
        conn = get_db_connection()
        if not conn:
            print("âŒ Database connection failed")
            return False
        
        cursor = conn.cursor()
        
        # Check if AI generation is enabled
        cursor.execute("SELECT setting_value FROM settings WHERE setting_key = 'ai_generation_enabled'")
        ai_enabled = cursor.fetchone()
        if not ai_enabled or ai_enabled['setting_value'] != 'true':
            print("â„¹ï¸ AI generation is disabled in settings")
            cursor.close()
            conn.close()
            return False
        
        # Get settings
        cursor.execute("SELECT setting_key, setting_value FROM settings WHERE setting_key IN ('posts_per_day', 'auto_publish_enabled', 'content_freshness_days')")
        settings_result = cursor.fetchall()
        settings = {row['setting_key']: row['setting_value'] for row in settings_result}
        
        posts_per_day = int(settings.get('posts_per_day', '3'))
        auto_publish = settings.get('auto_publish_enabled', 'true') == 'true'
        freshness_days = int(settings.get('content_freshness_days', '7'))
        
        # Get active topics
        cursor.execute("""
            SELECT t.*, c.name as category_name 
            FROM topics t LEFT JOIN category c ON t.category_id = c.id 
            WHERE t.is_active = TRUE 
            ORDER BY t.priority DESC, RANDOM() 
            LIMIT %s
        """, (posts_per_day * 2,))  # Get more topics than needed for variety
        
        topics = cursor.fetchall()
        
        if not topics:
            print("â„¹ï¸ No active topics found")
            cursor.close()
            conn.close()
            return False
        
        generated_count = 0
        
        # Generate posts up to the daily limit
        for i in range(min(posts_per_day, len(topics))):
            topic = topics[i]
            
            # Check if we already generated content for this topic recently
            cursor.execute("""
                SELECT COUNT(*) as count FROM post 
                WHERE title ILIKE %s AND created_at >= %s AND is_ai_generated = TRUE
            """, (f'%{topic["name"]}%', datetime.utcnow() - timedelta(days=freshness_days)))
            
            recent_count = cursor.fetchone()['count']
            if recent_count > 0:
                print(f"â­ï¸ Skipping {topic['name']} - recent content exists")
                continue
            
            # Generate AI content
            ai_content = generate_ai_content_advanced(topic['name'], topic['category_name'] or 'Blockchain')
            
            if ai_content:
                # Create slug
                slug = create_slug(ai_content['title'])
                
                # Ensure unique slug
                counter = 1
                original_slug = slug
                while True:
                    cursor.execute("SELECT id FROM post WHERE slug = %s", (slug,))
                    if not cursor.fetchone():
                        break
                    slug = f"{original_slug}-{counter}"
                    counter += 1
                
                # Insert the post
                cursor.execute("""
                    INSERT INTO post (
                        title, slug, content, excerpt, category_id, 
                        is_published, is_ai_generated, author, 
                        include_in_sitemap, reading_time
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    ai_content['title'],
                    slug,
                    ai_content['content'],
                    ai_content['excerpt'],
                    topic['category_id'],
                    auto_publish,
                    True,
                    'AI Assistant',
                    True,
                    ai_content.get('reading_time', 5)
                ))
                
                post_id = cursor.lastrowid
                
                # Log the AI generation
                cursor.execute("""
                    INSERT INTO ai_posts (topic_id, post_id, ai_model, generation_time) 
                    VALUES (%s, %s, %s, %s)
                """, (topic['id'], post_id, 'GPT-Template', datetime.utcnow()))
                
                # Update topic last_generated time
                cursor.execute("""
                    UPDATE topics SET last_generated = %s, generation_count = generation_count + 1 
                    WHERE id = %s
                """, (datetime.utcnow(), topic['id']))
                
                generated_count += 1
                print(f"âœ… Generated post: {ai_content['title'][:50]}...")
        
        conn.commit()
        cursor.close()
        conn.close()
        
        print(f"ðŸŽ‰ Successfully generated {generated_count} AI posts")
        return generated_count > 0
        
    except Exception as e:
        print(f"âŒ Error in AI generation: {e}")
        return False

# Manual trigger route for testing
@app.route('/admin/ai-scheduler/generate-now', methods=['POST'])
@login_required
def manual_generate_posts():
    """Manually trigger AI post generation"""
    try:
        success = generate_posts_from_topics()
        if success:
            flash('AI posts generated successfully!', 'success')
        else:
            flash('No posts were generated. Check your topics and settings.', 'warning')
    except Exception as e:
        flash(f'Error generating posts: {str(e)}', 'error')
    
    return redirect(url_for('admin_dashboard'))

def start_ai_scheduler():
    """Start the AI content generation scheduler"""
    def run_scheduler():
        while True:
            try:
                schedule.run_pending()
                time.sleep(60)  # Check every minute
            except Exception as e:
                print(f"Scheduler error: {e}")
                time.sleep(300)  # Wait 5 minutes on error
    
    # Start scheduler in a separate thread
    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    print("ðŸ¤– AI Scheduler started successfully")

def update_ai_schedule():
    """Update the AI generation schedule based on current settings"""
    try:
        conn = get_db_connection()
        if not conn:
            return
        
        cursor = conn.cursor()
        cursor.execute("""
            SELECT setting_key, setting_value FROM settings 
            WHERE setting_key IN ('generation_schedule_time', 'generation_interval_hours', 'random_timing_enabled')
        """)
        settings_result = cursor.fetchall()
        settings = {row['setting_key']: row['setting_value'] for row in settings_result}
        
        cursor.close()
        conn.close()
        
        # Clear existing schedule
        schedule.clear()
        
        # Set up new schedule
        schedule_time = settings.get('generation_schedule_time', '09:00')
        interval_hours = int(settings.get('generation_interval_hours', '24'))
        random_timing = settings.get('random_timing_enabled', 'false') == 'true'
        
        if random_timing:
            # Schedule random times throughout the day
            for _ in range(24 // interval_hours):
                random_hour = random.randint(0, 23)
                random_minute = random.randint(0, 59)
                schedule.every().day.at(f"{random_hour:02d}:{random_minute:02d}").do(generate_posts_from_topics)
        else:
            # Schedule at specific intervals
            if interval_hours >= 24:
                schedule.every().day.at(schedule_time).do(generate_posts_from_topics)
            else:
                schedule.every(interval_hours).hours.do(generate_posts_from_topics)
        
        print(f"ðŸ“… AI schedule updated: {schedule_time}, every {interval_hours}h, random: {random_timing}")
        
    except Exception as e:
        print(f"Error updating schedule: {e}")


# Initialize AI scheduler when app starts
if __name__ == '__main__':
    # Start the AI scheduler
    start_ai_scheduler()
    update_ai_schedule()
    
    # Try to generate initial posts if none exist
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) as count FROM post")
            post_count = cursor.fetchone()['count']
            if post_count == 0:
                print("ðŸš€ No posts found, generating initial content...")
                generate_posts_from_topics()
            cursor.close()
            conn.close()
    except Exception as e:
        print(f"Initial generation check failed: {e}")
    
    port = int(os.getenv('APP_PORT', 5000))
    debug = os.getenv('FLASK_ENV') == 'development'
    
    print("ðŸš€ Starting Blockchain Latest News Platform...")
    print("ðŸŒ Public: https://blockchainlatestnews.com")
    print("ðŸ” Admin: https://blockchainlatestnews.com/admin")
    print("ðŸ¤– AI Scheduler: Active")
    
    app.run(host='0.0.0.0', port=port, debug=debug)

# Add missing topic management routes
@app.route('/admin/topics/edit', methods=['POST'])
@login_required
def admin_edit_topic():
    try:
        topic_id = request.form.get('topic_id')
        topic_name = request.form.get('topic_name', '').strip()
        topic_description = request.form.get('topic_description', '').strip()
        category_id = request.form.get('category_id') or None
        is_active = 'is_active' in request.form
        
        if not topic_name or not topic_id:
            flash('Topic name and ID are required', 'error')
            return redirect(url_for('admin_topics'))
        
        conn = get_db_connection()
        if not conn:
            flash('Database connection error', 'error')
            return redirect(url_for('admin_topics'))
        
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE topics SET 
            name = %s, description = %s, category_id = %s, is_active = %s, updated_at = CURRENT_TIMESTAMP
            WHERE id = %s
        """, (topic_name, topic_description, category_id, is_active, topic_id))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        flash('Topic updated successfully!', 'success')
        return redirect(url_for('admin_topics'))
        
    except Exception as e:
        flash(f'Error updating topic: {str(e)}', 'error')
        return redirect(url_for('admin_topics'))

@app.route('/admin/topics/generate', methods=['POST'])
@login_required
def generate_single_topic():
    try:
        data = request.get_json()
        topic_id = data.get('topic_id')
        
        if not topic_id:
            return jsonify({'success': False, 'message': 'Topic ID required'})
        
        conn = get_db_connection()
        if not conn:
            return jsonify({'success': False, 'message': 'Database connection error'})
        
        cursor = conn.cursor()
        
        # Get topic details
        cursor.execute("""
            SELECT t.*, c.name as category_name 
            FROM topics t LEFT JOIN category c ON t.category_id = c.id 
            WHERE t.id = %s
        """, (topic_id,))
        topic = cursor.fetchone()
        
        if not topic:
            return jsonify({'success': False, 'message': 'Topic not found'})
        
        # Generate AI content
        ai_content = generate_ai_content_advanced(topic['name'], topic['category_name'] or 'Blockchain')
        
        if not ai_content:
            return jsonify({'success': False, 'message': 'Failed to generate content'})
        
        # Create slug
        slug = create_slug(ai_content['title'])
        counter = 1
        original_slug = slug
        while True:
            cursor.execute("SELECT id FROM post WHERE slug = %s", (slug,))
            if not cursor.fetchone():
                break
            slug = f"{original_slug}-{counter}"
            counter += 1
        
        # Insert the post
        cursor.execute("""
            INSERT INTO post (
                title, slug, content, excerpt, category_id, 
                is_published, is_ai_generated, author, 
                include_in_sitemap, reading_time
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            RETURNING id
        """, (
            ai_content['title'],
            slug,
            ai_content['content'],
            ai_content['excerpt'],
            topic['category_id'],
            True,  # Auto-publish
            True,
            'AI Assistant',
            True,
            ai_content.get('reading_time', 5)
        ))
        
        post_id = cursor.fetchone()['id']
        
        # Update topic stats
        cursor.execute("""
            UPDATE topics SET 
            last_generated = CURRENT_TIMESTAMP, 
            generation_count = COALESCE(generation_count, 0) + 1 
            WHERE id = %s
        """, (topic_id,))
        
        # Add to generation log
        cursor.execute("""
            INSERT INTO ai_posts (topic_id, post_id, ai_model, generation_time) 
            VALUES (%s, %s, %s, %s)
        """, (topic_id, post_id, 'GPT-Advanced-Template', datetime.utcnow()))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return jsonify({
            'success': True, 
            'message': 'Content generated successfully!',
            'post_title': ai_content['title'],
            'post_id': post_id
        })
        
    except Exception as e:
        print(f"Single topic generation error: {e}")
        return jsonify({'success': False, 'message': f'Generation error: {str(e)}'})

@app.route('/admin/topics/delete', methods=['POST'])
@login_required
def delete_topic():
    try:
        data = request.get_json()
        topic_id = data.get('topic_id')
        
        if not topic_id:
            return jsonify({'success': False, 'message': 'Topic ID required'})
        
        conn = get_db_connection()
        if not conn:
            return jsonify({'success': False, 'message': 'Database connection error'})
        
        cursor = conn.cursor()
        
        # Delete related AI posts first
        cursor.execute("DELETE FROM ai_posts WHERE topic_id = %s", (topic_id,))
        
        # Delete the topic
        cursor.execute("DELETE FROM topics WHERE id = %s", (topic_id,))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return jsonify({'success': True, 'message': 'Topic deleted successfully'})
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'Delete error: {str(e)}'})

# Queue management system
import queue
import uuid

# Global task queue
task_queue = queue.PriorityQueue()
completed_tasks = []
failed_tasks = []
scheduler_paused = False

class Task:
    def __init__(self, task_type, topic_id=None, topic_name=None, priority=1, scheduled_time=None):
        self.id = str(uuid.uuid4())
        self.type = task_type
        self.topic_id = topic_id
        self.topic_name = topic_name
        self.priority = priority
        self.scheduled_time = scheduled_time or datetime.utcnow()
        self.status = 'PENDING'
        self.created_at = datetime.utcnow()
    
    def __lt__(self, other):
        # Higher priority tasks first, then by scheduled time
        if self.priority != other.priority:
            return self.priority > other.priority
        return self.scheduled_time < other.scheduled_time

def add_task_to_queue(task_type, topic_id=None, topic_name=None, priority=1, scheduled_time=None):
    """Add a task to the queue"""
    task = Task(task_type, topic_id, topic_name, priority, scheduled_time)
    task_queue.put(task)
    print(f"ðŸ“‹ Added task to queue: {task_type} for {topic_name} (Priority: {priority})")
    return task.id

def process_queue_worker():
    """Background worker to process queue tasks"""
    while True:
        try:
            if scheduler_paused:
                time.sleep(30)
                continue
            
            if not task_queue.empty():
                task = task_queue.get(timeout=60)
                
                # Check if it's time to execute
                if task.scheduled_time <= datetime.utcnow():
                    task.status = 'RUNNING'
                    print(f"ðŸƒ Processing task: {task.type} for {task.topic_name}")
                    
                    try:
                        if task.type == 'AI_GENERATION':
                            # Process AI generation task
                            if task.topic_id:
                                success = generate_single_topic_backend(task.topic_id)
                            else:
                                success = generate_posts_from_topics()
                            
                            if success:
                                task.status = 'COMPLETED'
                                completed_tasks.append(task)
                                print(f"âœ… Completed task: {task.type}")
                            else:
                                task.status = 'FAILED'
                                failed_tasks.append(task)
                                print(f"âŒ Failed task: {task.type}")
                        
                    except Exception as e:
                        task.status = 'FAILED'
                        failed_tasks.append(task)
                        print(f"âŒ Task failed with error: {e}")
                else:
                    # Put task back if not time yet
                    task_queue.put(task)
                    time.sleep(60)
            else:
                time.sleep(60)
                
        except queue.Empty:
            time.sleep(60)
        except Exception as e:
            print(f"Queue worker error: {e}")
            time.sleep(60)

def generate_single_topic_backend(topic_id):
    """Backend function to generate content for a single topic"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        
        cursor = conn.cursor()
        cursor.execute("""
            SELECT t.*, c.name as category_name 
            FROM topics t LEFT JOIN category c ON t.category_id = c.id 
            WHERE t.id = %s AND t.is_active = TRUE
        """, (topic_id,))
        topic = cursor.fetchone()
        
        if not topic:
            cursor.close()
            conn.close()
            return False
        
        ai_content = generate_ai_content_advanced(topic['name'], topic['category_name'] or 'Blockchain')
        if not ai_content:
            cursor.close()
            conn.close()
            return False
        
        slug = create_slug(ai_content['title'])
        counter = 1
        original_slug = slug
        while True:
            cursor.execute("SELECT id FROM post WHERE slug = %s", (slug,))
            if not cursor.fetchone():
                break
            slug = f"{original_slug}-{counter}"
            counter += 1
        
        cursor.execute("""
            INSERT INTO post (
                title, slug, content, excerpt, category_id, 
                is_published, is_ai_generated, author, 
                include_in_sitemap, reading_time
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            RETURNING id
        """, (
            ai_content['title'], slug, ai_content['content'], ai_content['excerpt'],
            topic['category_id'], True, True, 'AI Assistant', True,
            ai_content.get('reading_time', 5)
        ))
        
        post_id = cursor.fetchone()['id']
        
        cursor.execute("""
            UPDATE topics SET 
            last_generated = CURRENT_TIMESTAMP, 
            generation_count = COALESCE(generation_count, 0) + 1 
            WHERE id = %s
        """, (topic_id,))
        
        cursor.execute("""
            INSERT INTO ai_posts (topic_id, post_id, ai_model, generation_time) 
            VALUES (%s, %s, %s, %s)
        """, (topic_id, post_id, 'Queue-Generated', datetime.utcnow()))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        print(f"âœ… Generated post: {ai_content['title'][:50]}...")
        return True
        
    except Exception as e:
        print(f"Backend generation error: {e}")
        return False

@app.route('/admin/queue/status')
@login_required
def queue_status():
    """Get current queue status"""
    try:
        # Get active tasks from queue
        active_tasks = []
        temp_tasks = []
        
        # Safely get tasks from queue without consuming them
        while not task_queue.empty():
            try:
                task = task_queue.get_nowait()
                temp_tasks.append(task)
                active_tasks.append({
                    'id': task.id,
                    'type': task.type,
                    'topic_name': task.topic_name or 'General',
                    'priority': task.priority,
                    'scheduled_time': task.scheduled_time.isoformat(),
                    'status': task.status
                })
            except queue.Empty:
                break
        
        # Put tasks back
        for task in temp_tasks:
            task_queue.put(task)
        
        # Get completed and failed tasks
        completed_list = [{
            'id': task.id,
            'type': task.type,
            'topic_name': task.topic_name or 'General',
            'priority': task.priority,
            'scheduled_time': task.scheduled_time.isoformat(),
            'status': task.status
        } for task in completed_tasks[-10:]]  # Last 10
        
        failed_list = [{
            'id': task.id,
            'type': task.type,
            'topic_name': task.topic_name or 'General',
            'priority': task.priority,
            'scheduled_time': task.scheduled_time.isoformat(),
            'status': task.status
        } for task in failed_tasks[-10:]]  # Last 10
        
        all_tasks = active_tasks + completed_list + failed_list
        
        return jsonify({
            'active': len(active_tasks),
            'completed': len(completed_tasks),
            'failed': len(failed_tasks),
            'pending': len([t for t in active_tasks if t['status'] == 'PENDING']),
            'tasks': all_tasks
        })
        
    except Exception as e:
        print(f"Queue status error: {e}")
        return jsonify({
            'active': 0,
            'completed': 0,
            'failed': 0,
            'pending': 0,
            'tasks': []
        })

@app.route('/admin/queue/next-generation')
@login_required
def next_generation_time():
    """Get next scheduled generation time"""
    try:
        conn = get_db_connection()
        if not conn:
            return jsonify({'next_time': 'Unknown'})
        
        cursor = conn.cursor()
        cursor.execute("""
            SELECT setting_value FROM settings 
            WHERE setting_key IN ('generation_schedule_time', 'generation_interval_hours')
        """)
        settings = {row['setting_key']: row['setting_value'] for row in cursor.fetchall()}
        cursor.close()
        conn.close()
        
        schedule_time = settings.get('generation_schedule_time', '09:00')
        interval_hours = int(settings.get('generation_interval_hours', '24'))
        
        # Calculate next generation time
        now = datetime.utcnow()
        next_time = now + timedelta(hours=interval_hours)
        
        return jsonify({
            'next_time': next_time.strftime('%I:%M %p'),
            'interval': interval_hours
        })
        
    except Exception as e:
        return jsonify({'next_time': 'Error'})

@app.route('/admin/queue/clear-completed', methods=['POST'])
@login_required
def clear_completed_tasks():
    global completed_tasks
    completed_tasks.clear()
    return jsonify({'success': True})

@app.route('/admin/queue/toggle-scheduler', methods=['POST'])
@login_required
def toggle_scheduler():
    global scheduler_paused
    scheduler_paused = not scheduler_paused
    return jsonify({'success': True, 'paused': scheduler_paused})

@app.route('/admin/queue/cancel-task', methods=['POST'])
@login_required
def cancel_task():
    try:
        data = request.get_json()
        task_id = data.get('task_id')
        
        # Remove task from queue (this is a simplified implementation)
        # In a real system, you'd need a more sophisticated queue management
        
        return jsonify({'success': True, 'message': 'Task cancelled'})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})

def schedule_hourly_tasks():
    """Schedule tasks based on settings"""
    try:
        conn = get_db_connection()
        if not conn:
            return
        
        cursor = conn.cursor()
        cursor.execute("""
            SELECT setting_value FROM settings 
            WHERE setting_key IN ('generation_interval_hours', 'posts_per_day', 'ai_generation_enabled')
        """)
        settings = {row['setting_key']: row['setting_value'] for row in cursor.fetchall()}
        
        if settings.get('ai_generation_enabled', 'true') == 'false':
            return
        
        interval_hours = int(settings.get('generation_interval_hours', '24'))
        posts_per_day = int(settings.get('posts_per_day', '3'))
        
        # Get active topics
        cursor.execute("SELECT id, name, priority FROM topics WHERE is_active = TRUE ORDER BY priority DESC")
        topics = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        # Schedule tasks for each topic based on priority
        now = datetime.utcnow()
        for i, topic in enumerate(topics[:posts_per_day]):
            # Schedule at intervals
            scheduled_time = now + timedelta(hours=i * (interval_hours / posts_per_day))
            add_task_to_queue(
                'AI_GENERATION',
                topic['id'],
                topic['name'],
                topic['priority'] or 1,
                scheduled_time
            )
        
        print(f"ðŸ“… Scheduled {len(topics[:posts_per_day])} tasks")
        
    except Exception as e:
        print(f"Task scheduling error: {e}")

def start_enhanced_scheduler():
    """Start the enhanced scheduler with queue management"""
    # Start queue worker thread
    queue_worker_thread = threading.Thread(target=process_queue_worker, daemon=True)
    queue_worker_thread.start()
    
    # Schedule initial tasks
    schedule_hourly_tasks()
    
    # Schedule recurring task scheduling
    def recurring_scheduler():
        while True:
            try:
                schedule_hourly_tasks()
                time.sleep(3600)  # Check every hour
            except Exception as e:
                print(f"Recurring scheduler error: {e}")
                time.sleep(300)  # Wait 5 minutes on error
    
    scheduler_thread = threading.Thread(target=recurring_scheduler, daemon=True)
    scheduler_thread.start()
    
    print("ðŸš€ Enhanced AI Scheduler with Queue Management started!")


# Fix the admin_edit_topic route
@app.route('/admin/topics/edit', methods=['POST'])
def admin_edit_topic():  # This function name must match the url_for() call
    try:
        topic_id = request.form.get('topic_id')
        topic_name = request.form.get('topic_name', '').strip()
        topic_description = request.form.get('topic_description', '').strip() 
        category_id = request.form.get('category_id') or None
        is_active = 'is_active' in request.form
        
        if not topic_name or not topic_id:
            flash('Topic name and ID are required', 'error')
            return redirect(url_for('admin_topics'))
        
        conn = get_db_connection()
        if not conn:
            flash('Database connection error', 'error')
            return redirect(url_for('admin_topics'))
        
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE topics SET 
            name = %s, description = %s, category_id = %s, is_active = %s, updated_at = CURRENT_TIMESTAMP
            WHERE id = %s
        """, (topic_name, topic_description, category_id, is_active, topic_id))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        flash('Topic updated successfully!', 'success')
        return redirect(url_for('admin_topics'))
        
    except Exception as e:
        flash(f'Error updating topic: {str(e)}', 'error')
        return redirect(url_for('admin_topics'))

# Add queue management routes
@app.route('/admin/queue')
@login_required
def admin_queue():
    """Admin Queue Management Dashboard"""
    try:  
        conn = get_db_connection()
        if not conn:
            return "Database connection failed"
        
        cursor = conn.cursor()
        
        # Get queued tasks from our task_queue table
        cursor.execute("""
            SELECT id, task_type, topic_name, priority, scheduled_time, status, created_at, error_message
            FROM task_queue 
            ORDER BY 
                CASE WHEN status = 'RUNNING' THEN 1 
                     WHEN status = 'PENDING' THEN 2 
                     WHEN status = 'COMPLETED' THEN 3 
                     ELSE 4 END,
                priority DESC, 
                scheduled_time ASC
            LIMIT 100
        """)
        tasks = cursor.fetchall()
        
        # Get queue statistics
        cursor.execute("""
            SELECT 
                status,
                COUNT(*) as count
            FROM task_queue 
            GROUP BY status
        """)
        stats_raw = cursor.fetchall()
        stats = {row['status']: row['count'] for row in stats_raw}
        
        # Get next scheduled task
        cursor.execute("""
            SELECT scheduled_time FROM task_queue 
            WHERE status = 'PENDING' AND scheduled_time > NOW()
            ORDER BY scheduled_time ASC LIMIT 1
        """)
        next_task = cursor.fetchone()
        next_scheduled = next_task['scheduled_time'] if next_task else None
        
        cursor.close()
        conn.close()
        
        return render_template('admin/queue.html',
                             tasks=tasks,
                             stats=stats,
                             next_scheduled=next_scheduled)
        
    except Exception as e:
        return f"Queue management error: {str(e)}"

@app.route('/admin/queue/cancel/<task_id>', methods=['POST'])
@login_required
def cancel_queue_task(task_id):
    """Cancel a specific task"""
    try:
        conn = get_db_connection()
        if not conn:
            flash('Database connection error', 'error')
            return redirect(url_for('admin_queue'))
        
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE task_queue SET 
            status = 'CANCELLED', 
            completed_at = CURRENT_TIMESTAMP,
            error_message = 'Cancelled by admin'
            WHERE id = %s AND status IN ('PENDING', 'RUNNING')
        """, (task_id,))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        flash('Task cancelled successfully', 'success')
        
    except Exception as e:
        flash(f'Error cancelling task: {str(e)}', 'error')
    
    return redirect(url_for('admin_queue'))

@app.route('/admin/queue/clear-completed', methods=['POST'])
@login_required
def clear_completed_tasks():
    """Clear all completed tasks"""
    try:
        conn = get_db_connection()
        if not conn:
            flash('Database connection error', 'error')
            return redirect(url_for('admin_queue'))
        
        cursor = conn.cursor()
        cursor.execute("DELETE FROM task_queue WHERE status IN ('COMPLETED', 'FAILED', 'CANCELLED')")
        deleted_count = cursor.rowcount
        
        conn.commit()
        cursor.close()
        conn.close()
        
        flash(f'Cleared {deleted_count} completed tasks', 'success')
        
    except Exception as e:
        flash(f'Error clearing tasks: {str(e)}', 'error')
    
    return redirect(url_for('admin_queue'))

@app.route('/admin/queue/pause-scheduler', methods=['POST'])
@login_required  
def pause_scheduler():
    """Pause/Resume the scheduler"""
    global scheduler_paused
    scheduler_paused = not scheduler_paused
    
    status = 'paused' if scheduler_paused else 'resumed'
    flash(f'Scheduler {status}', 'success')
    
    return redirect(url_for('admin_queue'))

# Improved scheduler initialization
def init_scheduler():
    """Initialize scheduler with database persistence"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        
        cursor = conn.cursor()
        
        # Check settings
        cursor.execute("""
            SELECT setting_key, setting_value FROM settings 
            WHERE setting_key IN ('ai_generation_enabled', 'generation_interval_hours', 'posts_per_day')
        """)
        settings = {row['setting_key']: row['setting_value'] for row in cursor.fetchall()}
        
        if settings.get('ai_generation_enabled', 'false') != 'true':
            print("â„¹ï¸ AI generation disabled")
            return False
        
        # Schedule initial tasks if none exist
        cursor.execute("SELECT COUNT(*) as count FROM task_queue WHERE status = 'PENDING'")
        pending_count = cursor.fetchone()['count']
        
        if pending_count == 0:
            # Add initial tasks
            posts_per_day = int(settings.get('posts_per_day', '3'))
            interval_hours = int(settings.get('generation_interval_hours', '24'))
            
            cursor.execute("SELECT id, name, priority FROM topics WHERE is_active = TRUE ORDER BY priority DESC LIMIT %s", (posts_per_day,))
            topics = cursor.fetchall()
            
            for i, topic in enumerate(topics):
                scheduled_time = datetime.utcnow() + timedelta(minutes=i * 10)  # Stagger by 10 minutes
                
                cursor.execute("""
                    INSERT INTO task_queue (task_type, topic_id, topic_name, priority, scheduled_time, status)
                    VALUES ('AI_GENERATION', %s, %s, %s, %s, 'PENDING')
                """, (topic['id'], topic['name'], topic['priority'] or 1, scheduled_time))
            
            conn.commit()
            print(f"ðŸ“… Scheduled {len(topics)} initial tasks")
        
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        print(f"Scheduler init error: {e}")
        return False

# Process pending tasks
def process_pending_tasks():
    """Process tasks that are due"""
    try:
        conn = get_db_connection()
        if not conn:
            return
        
        cursor = conn.cursor()
        
        # Get overdue tasks
        cursor.execute("""
            SELECT id, task_type, topic_id, topic_name 
            FROM task_queue 
            WHERE status = 'PENDING' AND scheduled_time <= NOW()
            ORDER BY priority DESC, scheduled_time ASC
            LIMIT 5
        """)
        overdue_tasks = cursor.fetchall()
        
        for task in overdue_tasks:
            try:
                # Mark as running
                cursor.execute("UPDATE task_queue SET status = 'RUNNING' WHERE id = %s", (task['id'],))
                conn.commit()
                
                print(f"ðŸƒ Processing task: {task['task_type']} for {task['topic_name']}")
                
                # Execute the task
                if task['task_type'] == 'AI_GENERATION' and task['topic_id']:
                    success = generate_single_topic_backend(task['topic_id'])
                else:
                    success = generate_posts_from_topics()
                
                # Update status
                if success:
                    cursor.execute("""
                        UPDATE task_queue SET 
                        status = 'COMPLETED', 
                        completed_at = CURRENT_TIMESTAMP 
                        WHERE id = %s
                    """, (task['id'],))
                    print(f"âœ… Completed task: {task['task_type']}")
                else:
                    cursor.execute("""
                        UPDATE task_queue SET 
                        status = 'FAILED', 
                        completed_at = CURRENT_TIMESTAMP,
                        error_message = 'Generation failed'
                        WHERE id = %s
                    """, (task['id'],))
                    print(f"âŒ Failed task: {task['task_type']}")
                
                conn.commit()
                
            except Exception as e:
                # Mark as failed
                cursor.execute("""
                    UPDATE task_queue SET 
                    status = 'FAILED', 
                    completed_at = CURRENT_TIMESTAMP,
                    error_message = %s
                    WHERE id = %s
                """, (str(e)[:500], task['id']))
                conn.commit()
                print(f"âŒ Task failed: {e}")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"Task processing error: {e}")

# Background scheduler thread
def scheduler_worker():
    """Background worker for processing tasks"""
    while True:
        try:
            if not scheduler_paused:
                process_pending_tasks()
            time.sleep(60)  # Check every minute
        except Exception as e:
            print(f"Scheduler worker error: {e}")
            time.sleep(300)  # Wait 5 minutes on error

# Start scheduler on app startup
if __name__ == '__main__':
    print("ðŸš€ Starting Blockchain Latest News Platform...")
    
    # Initialize scheduler
    if init_scheduler():
        # Start background scheduler
        scheduler_thread = threading.Thread(target=scheduler_worker, daemon=True)
        scheduler_thread.start()
        print("ðŸ¤– AI Scheduler started successfully")
    
    port = int(os.getenv('APP_PORT', 5000))
    debug = os.getenv('FLASK_ENV') == 'development'
    
    app.run(host='0.0.0.0', port=port, debug=debug, threaded=True)

# Improved scheduler initialization
def init_scheduler():
    """Initialize scheduler with database persistence"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        
        cursor = conn.cursor()
        
        # Check settings
        cursor.execute("""
            SELECT setting_key, setting_value FROM settings 
            WHERE setting_key IN ('ai_generation_enabled', 'generation_interval_hours', 'posts_per_day')
        """)
        settings = {row['setting_key']: row['setting_value'] for row in cursor.fetchall()}
        
        if settings.get('ai_generation_enabled', 'false') != 'true':
            print("â„¹ï¸ AI generation disabled")
            return False
        
        # Schedule initial tasks if none exist
        cursor.execute("SELECT COUNT(*) as count FROM task_queue WHERE status = 'PENDING'")
        pending_count = cursor.fetchone()['count']
        
        if pending_count == 0:
            # Add initial tasks
            posts_per_day = int(settings.get('posts_per_day', '3'))
            interval_hours = int(settings.get('generation_interval_hours', '24'))
            
            cursor.execute("SELECT id, name, priority FROM topics WHERE is_active = TRUE ORDER BY priority DESC LIMIT %s", (posts_per_day,))
            topics = cursor.fetchall()
            
            for i, topic in enumerate(topics):
                scheduled_time = datetime.utcnow() + timedelta(minutes=i * 10)  # Stagger by 10 minutes
                
                cursor.execute("""
                    INSERT INTO task_queue (task_type, topic_id, topic_name, priority, scheduled_time, status)
                    VALUES ('AI_GENERATION', %s, %s, %s, %s, 'PENDING')
                """, (topic['id'], topic['name'], topic['priority'] or 1, scheduled_time))
            
            conn.commit()
            print(f"ðŸ“… Scheduled {len(topics)} initial tasks")
        
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        print(f"Scheduler init error: {e}")
        return False

# Process pending tasks
def process_pending_tasks():
    """Process tasks that are due"""
    try:
        conn = get_db_connection()
        if not conn:
            return
        
        cursor = conn.cursor()
        
        # Get overdue tasks
        cursor.execute("""
            SELECT id, task_type, topic_id, topic_name 
            FROM task_queue 
            WHERE status = 'PENDING' AND scheduled_time <= NOW()
            ORDER BY priority DESC, scheduled_time ASC
            LIMIT 5
        """)
        overdue_tasks = cursor.fetchall()
        
        for task in overdue_tasks:
            try:
                # Mark as running
                cursor.execute("UPDATE task_queue SET status = 'RUNNING' WHERE id = %s", (task['id'],))
                conn.commit()
                
                print(f"ðŸƒ Processing task: {task['task_type']} for {task['topic_name']}")
                
                # Execute the task
                if task['task_type'] == 'AI_GENERATION' and task['topic_id']:
                    success = generate_single_topic_backend(task['topic_id'])
                else:
                    success = generate_posts_from_topics()
                
                # Update status
                if success:
                    cursor.execute("""
                        UPDATE task_queue SET 
                        status = 'COMPLETED', 
                        completed_at = CURRENT_TIMESTAMP 
                        WHERE id = %s
                    """, (task['id'],))
                    print(f"âœ… Completed task: {task['task_type']}")
                else:
                    cursor.execute("""
                        UPDATE task_queue SET 
                        status = 'FAILED', 
                        completed_at = CURRENT_TIMESTAMP,
                        error_message = 'Generation failed'
                        WHERE id = %s
                    """, (task['id'],))
                    print(f"âŒ Failed task: {task['task_type']}")
                
                conn.commit()
                
            except Exception as e:
                # Mark as failed
                cursor.execute("""
                    UPDATE task_queue SET 
                    status = 'FAILED', 
                    completed_at = CURRENT_TIMESTAMP,
                    error_message = %s
                    WHERE id = %s
                """, (str(e)[:500], task['id']))
                conn.commit()
                print(f"âŒ Task failed: {e}")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"Task processing error: {e}")

# Background scheduler thread
def scheduler_worker():
    """Background worker for processing tasks"""
    while True:
        try:
            if not scheduler_paused:
                process_pending_tasks()
            time.sleep(60)  # Check every minute
        except Exception as e:
            print(f"Scheduler worker error: {e}")
            time.sleep(300)  # Wait 5 minutes on error

# Start scheduler on app startup
if __name__ == '__main__':
    print("ðŸš€ Starting Blockchain Latest News Platform...")
    
    # Initialize scheduler
    if init_scheduler():
        # Start background scheduler
        scheduler_thread = threading.Thread(target=scheduler_worker, daemon=True)
        scheduler_thread.start()
        print("ðŸ¤– AI Scheduler started successfully")
    
    port = int(os.getenv('APP_PORT', 5000))
    debug = os.getenv('FLASK_ENV') == 'development'
    
    app.run(host='0.0.0.0', port=port, debug=debug, threaded=True)
